---
layout: post
title: "How do I backup to Amazon S3 storage service"
date: 2006-11-20
comments: false
---

<div class='post'>
All of today I spent putting together all the tools to do an incremental backup to the <a href="http://www.amazon.com/S3-AWS-home-page-Money/b/ref=sc_fe_l_2/002-9228059-8329637?ie=UTF8&node=16427261&amp;amp;no=3435361&amp;me=A36L942TSJ2AJA">Amazon S3 storage service</a>.<br /><br />Amazon is a good brand and providing storage as service is very good utility. But I was not very happy by the fact that Amazon has tried to reinvent storage with this web service.  Web Services are a good interface for remote inter process communication. But why do storage operations like function calls. Anyway, cheap cost of the offered storage and good brand were enough for me to pursue it as my backup solution.<br /><br />I spent whole evening setting up <a href="http://jeremy.zawodny.com/blog/archives/007641.html?">different tools</a> that provide front end for S3 service. The most useful tool would be a NAS server that provides NFS/CIFS mounts and does S3 transactions at the backend. However it was hard to find any such direct tool. As of today there are many under-development or beta scripts written in perl, python, ruby, java. I gave a shot to few of them, but they weren't very handy for solving my simple backup solution. <a href="http://www.jungledisk.com/">JungleDisk</a> is very good frontend tool for S3-service. It gives WebDAV frontend interface (again why WebDAV and not NSF?) and it's available for all platforms. It is good if your needs are manual access to this storage. It is difficult to treat WebDAV URL as a drive so that a backup utility can write to it just like any other local drive. I investigated <a href="http://www.webdav.org/projects/">lot of options</a>, NFS-to-WebDAV bridge, WebDAV CLI clients which can be called by backup scripts, but there isn't a great solution for all platforms. My current need is Windows desktop backup. Finally I got 'S3Drive'. It mounts the S3 storage as just another drive on your windows box. This was gr8 for my current needs. One thing to note - JungleDisk does not show the files stored by other front end tools to the same S3 bucket - it didn't show the files stored by <a href="http://www.suchwerk.net/sodcms_S3Drive_at_work.htm">S3Drive</a>.  There are some other tools however which show objects stored by other tools as well, e.g. <a href="http://www.lumensystems.com/s3safe.aspx">S3Safe</a>.<br /><br />So storage is ready, now the backup software. I was using <a href="http://www.rdcomp.net/ezbackitup/">EzBack-it-up</a>. But after reading through its docs, I realized that it is very dumb in doing incremental backups. I had considered WinRAR some time back as backup option, but didn't get its archiving logic. After reading thru some documentation and its CLI options I figured out a way to do incremental backups.  When its CLI tool is run with -ao option it "adds files with Archive attribute set". With -ac option it "Clears Archive attribute after compression or extraction". Thus "rar a -ao -ac backup.tar <list>" will backup only the files that have changed since last backup (unless someone else changes the archive flag - I need to check with my CVS tools for this). So I got incremental backup tool.<br /><br />How to enforce policies and schedules. <a href="http://www.cronforwindows.com/">CronForWindows</a> solves schedules problem. I spent better part of an hour on very minute problem. Being alergic to BATCH files I couldn't find a programmatic way to create the unique target tar file name that will have timestamp embedded in it. I tried running bash script using cygwin, but backslashes and/or '%' symbols in date command format caused problems. I thought of writing quick java code, but thought that wasn't really quick. So I decided to give python a shot. After half an hour I came up with following script:<br /></list><pre><br />from datetime import date<br />import os<br /><br />today=date.today()<br />today_str = "%s%s%s"%(today.month,today.day,today.year)<br />command = 'rar a -ac -ao'+'b:\e%s'%today_str+'.tar'+' c:\workspace\project'<br />os.system(command)<br /></pre><br />I had to put rar.exe in one of the directories in PATH, but it worked. The Cron scheduler can run this script as per the schedule I set.<br /><br />I have few MBs of source directory that I need to backup. I expect its contents to change under an MB per day. Looks like pretty good deal with cheap prices of S3 service.</div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>iPad Game Development</div>
<div class='content'>
This comment has been removed by a blog administrator.</div>
</div>
<div class='comment'>
<div class='author'>Frank Diaz</div>
<div class='content'>
How do you use Syncback to write to S3?</div>
</div>
<div class='comment'>
<div class='author'>Anonymous</div>
<div class='content'>
Give <A HREF="http://www.2brightsparks.com/downloads.html#freeware" REL="nofollow">SyncBack </A>a try. Does incremental backups etc. Works like a charm.</div>
</div>
<div class='comment'>
<div class='author'>Jayesh</div>
<div class='content'>
No I haven't tried many windows backup solutions. But <A HREF="http://forum.jungledisk.com/viewtopic.php?p=2636&sid=57fd3431125d29a0a5b651b766a17c0b" REL="nofollow">some investigation</A><BR/> shows that robocopy has problems doing backups to WebDav drives.<BR/><BR/><BR/>Right now S3 storage interface is few steps away from filesystem interface. When this gap is filled in by someone - either S3 wrapper softwares OR backup softwares - we will have portable backup solution.<BR/><BR/>Thanks for the comment though.</div>
</div>
<div class='comment'>
<div class='author'>Eric</div>
<div class='content'>
Have you tried using Robocopy to do backups to the network s3drive?</div>
</div>
<div class='comment'>
<div class='author'>Anonymous</div>
<div class='content'>
S3Drive is a CIFS server and the buckets can be mounted like Windows shares, so there is no need for a NAS server.</div>
</div>
</div>
